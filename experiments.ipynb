{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "\n",
    "data_path = 'INRIAPerson/'\n",
    "annot_path = join(data_path, 'Train/annotations/')\n",
    "annotation_paths = [join(annot_path, p) for p in os.listdir(annot_path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsePascalFormat(lines, root):\n",
    "    image_path = lines[2].split(' ')[-1][1:-1]\n",
    "    annots = list(filter(lambda l: l != '', lines[12:]))\n",
    "    \n",
    "    parsed_annots = [\n",
    "        annots[i].translate({ord(c): None for c in '()-,'}).split(' ')[-5:]\n",
    "        for i in range(5, len(annots), 6)\n",
    "    ]\n",
    "    \n",
    "    bb = [\n",
    "        [int(a[0]), int(a[1]), int(a[3]), int(a[4])]\n",
    "        for a in parsed_annots\n",
    "    ]\n",
    "    return join(root, image_path), bb\n",
    "\n",
    "def readFile(path):\n",
    "    with open(path, 'r') as f:\n",
    "        return f.read()\n",
    "    \n",
    "def bb_normalise(bbs, path):\n",
    "    image = imread(path)\n",
    "    h, w = image.shape[:2]\n",
    "    return [[\n",
    "        int(bb[0] / w * IM_SIZE),\n",
    "        int(bb[1] / h * IM_SIZE),\n",
    "        int(bb[2] / w * IM_SIZE),\n",
    "        int(bb[3] / h * IM_SIZE)\n",
    "    ] for bb in bbs]\n",
    "\n",
    "def drawImageBB(path, boundingboxes):\n",
    "    rsz_image = imresize(imread(path), (IM_SIZE, IM_SIZE))\n",
    "    ax = plt.imshow(rsz_image)\n",
    "    \n",
    "    for bb in boundingboxes:\n",
    "        left_bottom = (bb[0], bb[1]) \n",
    "        width = bb[2] - bb[0]\n",
    "        height = bb[3] - bb[1]\n",
    "\n",
    "        ax.axes.add_patch(patches.Rectangle(\n",
    "            left_bottom, width, height, fill=False, color='r'\n",
    "        ))\n",
    "        \n",
    "    plt.show()\n",
    "    \n",
    "def overlap(a, b):\n",
    "    (ya1, xa1, ya2, xa2) = a\n",
    "    (yb1, xb1, yb2, xb2) = b\n",
    "    horizontal_overlap = np.maximum(0, np.minimum(xa2, xb2) - np.maximum(xa1, xb1))\n",
    "    vertical_overlap = np.maximum(0, np.minimum(ya2, yb2) - np.maximum(ya1, yb1))\n",
    "    return horizontal_overlap * vertical_overlap\n",
    "\n",
    "def area(a):\n",
    "    (y1, x1, y2, x2) = a\n",
    "    return (y2 - y1) * (x2 - x1)\n",
    "\n",
    "def IOU(a, b):\n",
    "    intersection = overlap(a, b)\n",
    "    return intersection / (area(a) + area(b) - intersection)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.misc import imread, imresize\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patches\n",
    "import numpy as np\n",
    "\n",
    "IM_SIZE = 416\n",
    "CELL_SIZE = 32\n",
    "NUM_CELLS = IM_SIZE // CELL_SIZE\n",
    "\n",
    "annotations = [\n",
    "    parsePascalFormat(readFile(p).split('\\n'), data_path)\n",
    "    for p in annotation_paths\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from tiny_yolo_v2 import TinyYOLOv2\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "net = TinyYOLOv2(IM_SIZE)\n",
    "# net.loadWeightsFromDarknet('yolov2-tiny-voc.weights')\n",
    "net.loadWeightsFromKeras('yolov2_tiny_keras_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = annotations[190][0]\n",
    "\n",
    "image = imresize(imread(p), (IM_SIZE, IM_SIZE)) / 255\n",
    "boxes = net.forward(image)\n",
    "\n",
    "drawImageBB(p, boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.m.save('yolov2_tiny_keras_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- assign responsibility to one predictor per cell based on which predictor in that cell has highest current IOU with ground truth\n",
    "- normalise bounding box height and width to fall in 0 - 1\n",
    "- x, y bb coords = offsets of a particluar grid cell location"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
